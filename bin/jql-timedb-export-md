#! /usr/local/opt/python@3.9/bin/python3
"""
For jql concept management schema

This takes a given concept and produces a page for it
"""

import collections
import datetime
import glob
import hashlib
import html
import json
import os
import pathlib
import random
import re
import shutil
import subprocess
import sys
import tempfile
import threading
import time
import urllib.parse

import requests

from http.server import BaseHTTPRequestHandler, HTTPServer

HOST_NAME = 'localhost'
PORT_NUMBER = 8080
MEMOS_PORT_NUMBER = 8081


def markdown_table(rows):
    rows.insert(1, ["-"] * len(rows[0]))

    def format_cell(s):
        if s[:2] == " *":
            s = "•" + s[2:]
        return s.replace("\n *", "\n•").replace("\n", "<br/>")

    if not any(rows):
        return ""
    return "\n".join("| {} |".format(" | ".join(map(format_cell, row)))
                     for row in rows)


def format_related(parent_full_pk, child_full_pk):
    """
    Remove common prefix and suffix for easier reading
    """
    # NOTE when we break out context codes and ordinals we should be
    # able to just use the shortname/description
    child_parts = child_full_pk.split(" ")
    parent_parts = parent_full_pk.split(" ")
    while child_parts and parent_parts and child_parts[0] == parent_parts[0]:
        child_parts.pop(0)
        parent_parts.pop(0)
    while child_parts and parent_parts and child_parts[-1] == parent_parts[-1]:
        child_parts.pop()
        parent_parts.pop()
    return " ".join(child_parts)


def _render_link(description, target, new_window=False):
    if new_window:
        return "[{}]({})".format(description, urllib.parse.quote(target))
    return '<a href="{}">{}</a>'.format(urllib.parse.quote(target),
                                        description)


def pluralize(word):
    # HACK a few rules for pluralization
    if word.endswith("y") and len(word) > 2 and word[-2] not in "aeou":
        return word[:-1] + "ies"
    return f"{word}s" if not word.endswith("s") else f"{word}es"


def tabulate_entries(page_pk, full_pks, key2rel2orobs):
    all_relations = sorted(
        {rel
         for pk in full_pks for rel in key2rel2orobs[pk]})
    # HACK descriptions end up taking too much space in large tables
    if len(all_relations) >= 5 and "Description" in all_relations:
        all_relations.remove("Description")
    table = [[""] + sorted(all_relations)]
    for full_pk in full_pks:
        display_name = format_related(page_pk, full_pk)
        row = [_render_link(display_name, "/" + full_pk)]
        table.append(row)
        for rel in all_relations:
            orobs = key2rel2orobs[full_pk][rel]
            # NOTE tight coupling with parent procedure here that constructs
            # pseudo "Meta" relations for Points, Thoughts, &c
            if rel == "Meta":
                counts = collections.Counter(
                    [orig_rel for orig_rel, _ in orobs])
                row.append("\n".join(f"{v} {pluralize(k)}"
                                     for k, v in counts.items()))
            elif len(orobs) == 0:
                row.append("")
            elif len(orobs) == 1:
                row.append(orobs[0][1].split("\n\n")[0].rstrip())
            else:
                row.append(f"{len(orobs)} items")
    return table


def generate_markdown(snapshot, table, pk):
    # TODO a lot of these mappings are invariant and can be cached
    full_pk = "{} {}".format(table, pk)
    get_candidate_parents = lambda row: set(
        map(row.get, ["Parent", "Direct", "Indirect", "Primary Goal"]))
    search_tables = ["nouns", "tasks"]
    children = {
        "{} {}".format(tab, k): v
        for tab in search_tables
        # TODO should check if the table matches as well
        for k, v in snapshot[tab].items() if pk in get_candidate_parents(v)
    }
    # NOTE full_pk_2_sort_key and key2rel2orobs are both general purpose mappings
    # that we can generate and cache every time we reload the table

    # When tabulating entries, sort in descending order of start date -- children that
    # don't have (e.g. nouns) take priority -- further sort in reverse lexicographic order from there
    full_pk_2_sort_key = {
        f"{tab} {pk}": (entry.get("Param~Start", sys.maxsize), pk)
        for tab in search_tables for pk, entry in snapshot[tab].items()
    }
    sort_related = lambda pks: sorted(pks, key=full_pk_2_sort_key.get)

    assertions = snapshot["assertions"]
    key2rel2orobs = collections.defaultdict(
        lambda: collections.defaultdict(list))
    meta_rels = [
        "Conclusion", "Point", "Thought", "Resource", "Quote", "Procedure",
        "Memo"
    ]
    for key, value in assertions.items():
        rel_pk = value["Arg0"]
        if not value["A Relation"].startswith("."):
            continue
        rel = value["A Relation"][1:]
        if rel in meta_rels and rel_pk != full_pk:
            l = len(key2rel2orobs[rel_pk]["Meta"])
            key2rel2orobs[rel_pk]["Meta"].append((rel, value["Arg1"]))
        else:
            key2rel2orobs[rel_pk][rel].append((value["Order"], value["Arg1"]))
    by_relation = key2rel2orobs[full_pk]
    description = by_relation.get("Description", [])
    if "Description" in by_relation:
        del by_relation["Description"]
    singletons = {
        rel
        for rel, orobs in by_relation.items()
        if len(orobs) == 1 and rel not in meta_rels
    }
    multitons = {
        rel
        for rel, orobs in by_relation.items()
        if len(orobs) != 1 or rel in meta_rels
    }
    title, subtitle = pk, ""
    if title.endswith(")"):
        # HACK assumes only one subexpression in parens
        title = pk.split("(", 1)[0]
        subtitle = pk.split("(", 1)[1][:-1]
    markdown = "# {}\n**{}**\n".format(title, subtitle)
    markdown += markdown_table(
        [["**{}**".format(header) for header in sorted(singletons)],
         [by_relation[header][0][1] for header in sorted(singletons)]])
    markdown += "\n"
    if len(description) != 1:
        markdown += "\n".join(
            "* {}".format(orob[1])
            for orob in sorted(description, key=lambda orob: orob[0]))
    else:
        markdown += description[0][1]
    for multiton in sorted(multitons):
        sorted_multitons = sorted(by_relation[multiton],
                                  key=lambda orob: orob[0])
        markdown += f"\n## {pluralize(multiton)} ({len(sorted_multitons)})\n"

        def format_orob(orob):
            point = orob[1]
            if not (is_number_line(point) or is_named_line(point)):
                point = "* {}".format(point)
            return point

        markdown += "\n".join(map(format_orob, sorted_multitons))
    markdown += "\n## Related"
    markdown += f"\n### Children ({len(children)})\n"
    markdown += markdown_table(
        tabulate_entries(full_pk, sort_related(children), key2rel2orobs))

    cls2rel2subj = collections.defaultdict(
        lambda: collections.defaultdict(list))

    src2cls = {}
    for key, value in assertions.items():
        src, rel, tgt = map(value.get, ["Arg0", "A Relation", "Arg1"])
        if rel != ".Class" or not tgt.startswith(
                "@timedb:") or not tgt.endswith(":"):
            continue
        tgt_pk = tgt[len("@timedb:"):-1]
        if ":" in tgt_pk:
            continue
        src2cls[src] = tgt_pk
    # TODO would be good to cache a bidrectional map of assertions and to
    # refactor this method in general
    for key, value in assertions.items():
        src, rel, tgt = map(value.get, ["Arg0", "A Relation", "Arg1"])
        if not rel.startswith(".") or not tgt.startswith(
                "@timedb:") or not tgt.endswith(":"):
            continue
        tgt_pk = tgt[len("@timedb:"):-1]
        if ":" in tgt_pk:
            continue
        # NOTE for now timedb refs only support nouns as I haven't needed links to tasks
        # but this is one place where we would need to support them
        full_tgt_pk = f"nouns {tgt_pk}"
        if full_tgt_pk != full_pk:
            continue
        cls = src2cls.get(src, "Noun")
        cls2rel2subj[cls][rel[1:]].append(src)

    for cls, rel2subj in cls2rel2subj.items():
        for rel, subjects in rel2subj.items():
            markdown += f"\n### {pluralize(cls)} with this {rel} ({len(subjects)})\n"
            table = tabulate_entries(full_pk, sort_related(subjects),
                                     key2rel2orobs)
            markdown += markdown_table(table)
    return markdown


def get_modified(path):
    return datetime.datetime.fromtimestamp(pathlib.Path(path).stat().st_mtime)


def render_pic(src):
    wd = os.getcwd()
    target = "{}.svg".format(src[:-3])
    if not os.path.exists(target):
        subprocess.check_call([
            "docker",
            "run",
            "-i",
            "--rm",
            "--entrypoint=pp",
            "-w",
            wd,
            "-v",
            "{}:{}".format(wd, wd),
            "ulmenhaus/env",
            src,
        ])
    img = '<div style="text-align:center; padding-bottom: 25px;"><img src="/{}" /></div>\n'.format(
        target)
    return img


def resolve_jql_links(base_markdown):
    inputs = base_markdown.split("@timedb:")
    parts = []
    for i, inpt in enumerate(inputs):
        if i == 0:
            parts.append(inpt)
            continue
        # technically disallows to link with a noun that has a colon but shrug
        ref, rest = inpt.split(":", 1)
        parts.append(_render_link(ref, "/nouns " + ref))
        parts.append(rest)
    return "".join(parts)


def render_pics(grouped, meta):
    for i, group in enumerate(grouped):
        lines = group.split("\n")
        if lines[0] not in ["```pic.py", "```m4"]:
            yield group
            continue
        group_meta = meta.get(i, "").encode("utf-8")
        suffix = lines[0][3:]
        body = "\n".join(lines[1:-1]).encode("utf-8")
        sha = hashlib.sha256()
        sha.update(body)
        sha.update(b"\x00")
        sha.update(group_meta)
        dgst = sha.hexdigest()[:8]
        src = "build/{}.{}".format(dgst, suffix)
        meta_src = src + ".meta"
        if not os.path.exists(src):
            with open(src, 'wb') as f:
                f.write(body)
            with open(meta_src, 'wb') as f:
                f.write(group_meta)
        yield render_pic(src)


def inject_externals(default_project, markdown):
    suffix_to_language = {
        "py": "python",
    }
    lines = markdown.split("\n")
    grouped = []
    while lines:
        first = lines.pop(0)
        if first.startswith("```"):
            while lines:
                to_add = lines.pop(0)
                first += "\n" + to_add
                if to_add.startswith("```"):
                    break
        grouped.append(first)

    final = []
    meta = {}
    for i, group in enumerate(grouped):
        if group.startswith("```external"):
            lines = group.split("\n")
            meta[i] = "\n".join(lines[1:-1])
            args = lines[0].split(" ")[1:]
            filename = args[0]
            until = None
            after = None
            if ":" in filename:
                filename, section = filename.split(":")
                after = f"## start_section: {section}"
                until = f"## end_section: {section}"
            suffix = filename.split(".", 1)[1]
            if "/" not in filename:
                filename = "{}/{}".format(default_project, filename)
            filename = "snippets/{}".format(filename)

            for arg in args[1:]:
                if match := re.match('until="(?P<until>.*)"\Z', arg):
                    until = match.group("until")
                elif match := re.match('after="(?P<after>.*)"\Z', arg):
                    after = match.group("after")
            with open(filename) as f:
                body = f.read()
                if after:
                    body = body.split(after, 1)[1]
                if until:
                    body = body.split(until, 1)[0]
            group = "```{}\n{}\n```".format(
                suffix_to_language.get(suffix, suffix), body)
        final.append(group)

    final = render_pics(final, meta)
    return resolve_jql_links("\n".join(final))


class MarkdownHandler(BaseHTTPRequestHandler):
    snapshot = None
    template = None

    def do_HEAD(s):
        s.send_response(200)
        s.send_header("Content-type", "text/html")
        s.end_headers()

    def do_GET(s):
        s.send_response(200)
        full_pk = urllib.parse.unquote(s.path)[1:]
        if full_pk.endswith("favicon.ico"):
            return
        if full_pk.startswith("build"):
            if full_pk.endswith(".svg"):
                s.send_header("Content-type", "image/svg+xml")
            else:
                s.send_header("Content-type", "text/html")
            s.end_headers()
            with open(full_pk, 'rb') as f:
                s.wfile.write(f.read())
                return
        s.send_header("Content-type", "text/html")
        s.end_headers()
        table, pk = full_pk.split(" ", 1)
        project = "notes"
        if table == "writeup":
            project = pk.split("/")[0]
            with open(os.path.join("writeups", pk)) as f:
                markdown = f.read()
        else:
            markdown = generate_markdown(MarkdownHandler.snapshot, table, pk)
        markdown = inject_externals(project, markdown)
        contents = MarkdownHandler.template.replace(
            "{md-contents}",
            html.escape(markdown)).replace("{md-postfix}", "")
        s.wfile.write(contents.encode("utf-8"))


class MemosHandler(BaseHTTPRequestHandler):
    memos = None

    def do_HEAD(s):
        s.send_response(200)
        s.send_header("Content-type", "text/html")
        s.end_headers()

    def do_GET(s):
        s.send_response(200)
        req_url = urllib.parse.urlparse(s.path)
        queries = urllib.parse.parse_qs(req_url.query)
        full_pk = urllib.parse.unquote(req_url.path)[1:]
        if full_pk.endswith("favicon.ico"):
            return
        if full_pk.startswith("build/"):
            if full_pk.endswith(".svg"):
                s.send_header("Content-type", "image/svg+xml")
            else:
                s.send_header("Content-type", "text/html")
            s.end_headers()
            with open(full_pk, 'rb') as f:
                s.wfile.write(f.read())
                return
        key_to_parent_pk = {}
        selections = [
            ["#660000", "Hardest"],
            ["#bb0000", "Harder"],
            ["#ff0000", "Hard"],
            ["#006600", "Easy"],
            ["#00bb00", "Easier"],
            ["#00ff00", "Easiest"],
        ]
        sel2level = {selections[i][1]: i for i in range(len(selections))}
        show = 'show' in queries
        table, pk = full_pk.split(" ", 1)
        memos, memo2parent = MemosHandler.get_memos(full_pk)
        if 'sel' in queries:
            sel = queries['sel'][0]
            key = queries['key'][0]
            parent_pk = "{} {}".format(table, memo2parent[key])
            s.memos[parent_pk][key]['last_tested'] = int(time.time())
            s.memos[parent_pk][key]['history'].append(sel2level[sel])
            MemosHandler._save()
            # reload now that we've updated this entry
            memos, memo2parent = MemosHandler.get_memos(full_pk)
        s.send_header("Content-type", "text/html")
        s.end_headers()
        markdown = "All done for today"
        postfix = ""
        if memos:
            key, memo = random.choice(list(memos.items()))
            if show:
                key = queries['key'][0]
                memo = memos[key]
            if "\n" in memo['question']:
                markdown = memo['question']
            else:
                markdown = "## {}".format(memo['question'])

            if "\n" in memo['answer']:
                if show:
                    markdown += "\n" + memo['answer']
                else:
                    postfix = '<div align="center" id="answer" style="font-size: 20pt"><a href="?show=1&key={key}">Show Answer</a></div>'.format(
                        key=key)
            else:
                postfix = '''<div align="center" id="answer" style="font-size: 20pt"><a href="#" onclick="document.getElementById('answer').innerHTML = '{}'">Show Answer</a></div>'''.format(
                    memo['answer'].replace("'", r"\'"))
            postfix += '<div align="center" style="padding-top: 20px; font-size: 20pt">'
            for selection in selections:
                color, choice = selection
                postfix += '<span style="padding: 10px"><a href="?sel={sel}&key={key}" style="color: {color}">{choice}</a></span>'.format(
                    color=color, choice=choice, sel=choice, key=key)
            postfix += '</div>'
        markdown = inject_externals("notes", markdown)
        contents = MarkdownHandler.template.replace(
            "{md-contents}",
            html.escape(markdown)).replace("{md-postfix}", postfix)
        s.wfile.write(contents.encode("utf-8"))

    def get_memos(full_pk, recursive=True):
        table, pk = full_pk.split(" ", 1)
        pks = [pk]
        if recursive:
            stack = [pk]
            pks = []
            db = MarkdownHandler.snapshot
            node2children = collections.defaultdict(list)
            parent_key = 'Primary Goal' if table == 'tasks' else 'Parent'
            for pk, item in db[table].items():
                node2children[item[parent_key]].append(pk)
            while stack:
                pk = stack.pop()
                pks.append(pk)
                stack.extend(node2children[pk])

        # If the same memo appears in two parents, one will overwrite the other. This one will get
        # a new value in its history and will stop showing up so we no longer have an overwrite.
        memos, memo2parent = {}, {}
        for pk in pks:
            full_pk = "{} {}".format(table, pk)
            for key, memo in MemosHandler.memos[full_pk].items():
                # only write to memo2parent if we're going to show this one, otherwise a duplicate
                # could overwrite its parent on every trial and it would never go away
                if memo['last_tested'] is None:
                    memos[key] = memo
                    memo2parent[key] = pk
                else:
                    delay = sm2(memo['history'])
                    days_since = (int(time.time()) -
                                  memo['last_tested']) / (24 * 3600)
                    if days_since >= delay:
                        memos[key] = memo
                        memo2parent[key] = pk
        return memos, memo2parent

    def _key_for(q, a):
        key = hashlib.sha256()
        key.update(q.encode("utf-8"))
        key.update(b"\x00")
        key.update(a.encode("utf-8"))
        return key.hexdigest()[:8]

    def _sync_from_assertions():
        random.seed()
        memos = MemosHandler.memos
        local_memos = collections.defaultdict(dict)
        assns = MarkdownHandler.snapshot['assertions'].values()
        for assn in assns:
            subj = assn["Arg0"]
            relation = assn['A Relation']
            if relation == ".Memo":
                for q, a in MemosHandler.from_table(assn['Arg1']):
                    key = MemosHandler._key_for(q, a)
                    local_memos[subj][key] = (q, a)
            elif relation == ".Conclusion":
                for q, a in MemosHandler.from_conclusion(assn['Arg1']):
                    key = MemosHandler._key_for(q, a)
                    local_memos[subj][key] = (q, a)

        # first sync deletes
        for full_pk, pk_memos in memos.items():
            keys = list(pk_memos.keys())
            for key in keys:
                if key not in local_memos[full_pk]:
                    del memos[full_pk][key]
        for full_pk, pk_memos in local_memos.items():
            for key, pair in pk_memos.items():
                q, a = pair
                if key not in memos[full_pk]:
                    memos[full_pk][key] = {
                        "history": [],
                        "last_tested": None,
                        'question': q,
                        "answer": a,
                    }
        MemosHandler._save()

    def from_conclusion(txt):
        if not txt.startswith("**MEMO**"):
            return
        if "\n --\n" not in txt:
            print("skipping single-line MEMO as not implemented")
            return
        q, a = txt[len("**MEMO** "):].split("\n --\n")
        yield q, a
        yield a, q

    def from_table(tab):
        lines = tab.split("\n")[2:]
        if not lines:
            return
        elif not lines[0].startswith("|"):
            for singleton in tab.split("\n- ")[1:]:
                q, a = singleton.split("\n --\n")
                yield q, a
                yield a, q
            return

        cols = [col.strip() for col in lines[0].split("|")[1:-1]]
        rows = [[col.strip() for col in row.split("|")[1:-1]]
                for row in lines[2:] if row.startswith("|")]

        fore_name = cols[0]
        for colix in range(1, len(cols)):
            rev_name = cols[colix]
            for row in rows:
                fore = row[0]
                rev = row[colix]
                yield "{} for {}".format(fore_name, rev), fore
                yield "{} for {}".format(rev_name, fore), rev

    def _save():
        with open("memos.json", 'w') as f:
            json.dump(MemosHandler.memos, f, indent=4, sort_keys=True)


def export_to_html(project, pk):
    """
    Use a running codimd server with auto-export to convert markdown to html
    """
    with open(pk) as f:
        markdown = f.read()
    markdown = inject_externals(project, markdown)
    s = requests.Session()
    # HACK hardcode local username and password
    s.post("http://localhost:3000/login",
           data={
               "email": "john@smith.com",
               "password": "asdf"
           }).raise_for_status()
    resp = s.post(
        "http://localhost:3000/new",
        headers={"Content-type": "text/markdown"},
        data=markdown.encode('utf-8'),
        allow_redirects=False,
    )
    resp.raise_for_status()
    doc_url = "http://localhost:3000" + resp.headers['Location']
    subprocess.check_call(["open", doc_url])
    # HACK sleep five seconds to give it time to generate
    # and then get the latest file
    time.sleep(8)
    latest = max(glob.glob(os.path.expanduser("~/Downloads/*.html")),
                 key=get_modified)
    return latest


# TODO consolidate with jql-edit-properties by putting in lib
def is_number_line(line):
    first_word = line.split(" ", 1)[0]
    if len(first_word) < 2:
        return False
    if not first_word.endswith("."):
        return False
    for c in first_word[:-1]:
        if c < '0' or c > '9':
            return False
    return True


def is_named_line(line):
    return line.startswith("### ")


def sm2(x, a=6.0, b=-0.8, c=0.28, d=0.02, theta=0.2):
    """
    Returns the number of days to delay the next review of an item by, fractionally, based on the history of answers x to
    a given question, where
    x == 0: Incorrect, Hardest
    x == 1: Incorrect, Hard
    x == 2: Incorrect, Medium
    x == 3: Correct, Medium
    x == 4: Correct, Easy
    x == 5: Correct, Easiest
    @param x The history of answers in the above scoring.
    @param theta When larger, the delays for correct answers will increase.
    """
    assert all(0 <= x_i <= 5 for x_i in x)
    correct_x = [x_i >= 3 for x_i in x]
    # If you got the last question incorrect, just return 1
    if not correct_x[-1]:
        return 1.0

    # Calculate the latest consecutive answer streak
    num_consecutively_correct = 0
    for correct in reversed(correct_x):
        if correct:
            num_consecutively_correct += 1
        else:
            break

    return a * (max(
        1.3, 2.5 + sum(b + c * x_i + d * x_i * x_i
                       for x_i in x)))**(theta * num_consecutively_correct)


def _open_in_browser(memos=False):
    iface = json.load(sys.stdin)
    cv = iface['current_view']
    path = urllib.parse.quote("{} {}".format(cv['table'],
                                             cv['primary_selection']))
    port = MEMOS_PORT_NUMBER if memos else PORT_NUMBER
    subprocess.check_call(
        ["open", "http://{}:{}/{}".format(HOST_NAME, port, path)])


def _from_jql():
    iface = json.load(sys.stdin)
    snapshot = json.loads(iface["snapshot"])
    current_view = iface["current_view"]
    table = current_view["table"]
    pk = current_view["primary_selection"]
    if table == "nouns":
        table = "files"
        pk = snapshot["nouns"][pk]["Link"]
    if table != "files" or not pk.startswith("writeups/"):
        raise ValueError(
            "Markdown export to HTML not supported for anything but writeup files"
        )
    project = pk.split("/")[1]
    # we could do this in process, but sending to another pane gives better debug output
    #  name = pk.split("/")[-1].split(" ", 1)[1][:-3]
    #  out = export_to_html(project, pk)
    #  shutil.copyfile(out, "build/{}.html".format(name))
    subprocess.check_output([
        "tmux",
        "send",
        "-t",
        "right",
        "jql-timedb-export-md {} '{}'".format(project, pk),
        "ENTER",
    ])


def _watch_for_update(filepath, poll_interval=2):
    update_time = os.stat(filepath).st_mtime
    while True:
        time.sleep(poll_interval)
        new_time = os.stat(filepath).st_mtime
        if new_time != update_time:
            update_time = new_time
            # HACK jql might still be writing the file so sleep for another 100ms
            time.sleep(.1)
            yield


def _daemon():
    with open("schema2.json") as f:
        MarkdownHandler.snapshot = json.load(f)
    # TODO move this html into a package dir when I move these
    # lib functions into a package
    with open(os.path.join(os.path.dirname(__file__),
                           "fast-export-templ.html")) as f:
        MarkdownHandler.template = f.read()

    def watch_for_updates():
        for _ in _watch_for_update("schema2.json"):
            print("Time DB updated -- reloading")
            with open("schema2.json") as f:
                MarkdownHandler.snapshot = json.load(f)

    thread = threading.Thread(target=watch_for_updates, daemon=True)
    thread.start()
    httpd = HTTPServer(('localhost', PORT_NUMBER), MarkdownHandler)
    httpd.serve_forever()


def _memos_daemon():
    with open("schema2.json") as f:
        MarkdownHandler.snapshot = json.load(f)
    # TODO move this html into a package dir when I move these
    # lib functions into a package
    with open(os.path.join(os.path.dirname(__file__),
                           "fast-export-templ.html")) as f:
        MarkdownHandler.template = f.read()
    with open("memos.json") as f:
        MemosHandler.memos = collections.defaultdict(dict, json.load(f))
    MemosHandler._sync_from_assertions()

    def watch_for_updates():
        for _ in _watch_for_update("schema2.json"):
            print("Time DB updated -- reloading")
            with open("schema2.json") as f:
                MarkdownHandler.snapshot = json.load(f)
            MemosHandler._sync_from_assertions()

    thread = threading.Thread(target=watch_for_updates, daemon=True)
    thread.start()
    httpd = HTTPServer(('localhost', MEMOS_PORT_NUMBER), MemosHandler)
    httpd.serve_forever()


def _from_args():
    if len(sys.argv) == 2:
        project = "notes"
        path = sys.argv[1]
    elif len(sys.argv) == 3:
        project, path = sys.argv[1:]
    else:
        raise ValueError("Arguments must be [project] [file] or [file]")
    name = os.path.basename(path)
    if name.startswith("["):
        name = name.split("] ", 1)[1]
    if not name.endswith(".md"):
        raise ValueError("must export an md file", name)
    out = export_to_html(project, path)
    shutil.copyfile(out, "build/{}.html".format(name[:-3]))


def main():
    if "-d" in sys.argv:
        _daemon()
    elif "--open" in sys.argv:
        _open_in_browser("--memos" in sys.argv)
    elif "--memos" in sys.argv:
        _memos_daemon()
    elif len(sys.argv) > 1:
        _from_args()
    else:
        _from_jql()


if __name__ == "__main__":
    main()
